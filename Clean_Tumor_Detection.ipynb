{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP9+uMlK67EBmby2r1TwUP4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShyamSanthosh04/Liver-Cancer-Tumor-Detection/blob/main/Clean_Tumor_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "olbpbnX8bFMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "AxHPwYLob0aK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d falahgatea/liver-cancer-dataset"
      ],
      "metadata": {
        "id": "YdiYkbdqb2Bv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = '/content/liver-cancer-dataset.zip'\n",
        "output_path = '/content/output'\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(output_path)"
      ],
      "metadata": {
        "id": "TBfVHz2mcXWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "volume_dirs = ['/content/output/volume_pt1', '/content/output/volume_pt2',\n",
        "               '/content/output/volume_pt3', '/content/output/volume_pt4',\n",
        "               '/content/output/volume_pt5']\n",
        "segmentation_dir = '/content/output/segmentations'\n",
        "\n",
        "output_dir = '/content/dataset/processed'\n",
        "tumor_dir = os.path.join(output_dir, 'Tumor')\n",
        "no_tumor_dir = os.path.join(output_dir, 'NoTumor')\n",
        "\n",
        "os.makedirs(tumor_dir, exist_ok=True)\n",
        "os.makedirs(no_tumor_dir, exist_ok=True)\n",
        "\n",
        "image_size = (224, 224)\n",
        "min_tumor_area = 300\n",
        "\n",
        "def load_nifti(file_path):\n",
        "    img = nib.load(file_path)\n",
        "    return img.get_fdata()\n",
        "\n",
        "def process_data():\n",
        "    for vol_dir in volume_dirs:\n",
        "        for vol_file in os.listdir(vol_dir):\n",
        "            if vol_file.endswith('.nii'):\n",
        "                volume_path = os.path.join(vol_dir, vol_file)\n",
        "                volume_data = load_nifti(volume_path)\n",
        "\n",
        "                seg_file = vol_file.replace('volume', 'segmentation')\n",
        "                seg_path = os.path.join(segmentation_dir, seg_file)\n",
        "                seg_data = load_nifti(seg_path)\n",
        "\n",
        "                for i in range(volume_data.shape[2]):\n",
        "                    volume_slice = volume_data[:, :, i]\n",
        "                    seg_slice = seg_data[:, :, i]\n",
        "\n",
        "                    tumor_area = np.sum(seg_slice > 0)\n",
        "                    if tumor_area > min_tumor_area:\n",
        "                        output_path = os.path.join(tumor_dir, f\"{vol_file}_slice_{i}.png\")\n",
        "                    else:\n",
        "                        output_path = os.path.join(no_tumor_dir, f\"{vol_file}_slice_{i}.png\")\n",
        "\n",
        "                    resized_slice = cv2.resize(volume_slice, image_size)\n",
        "                    resized_slice = np.interp(resized_slice, (resized_slice.min(), resized_slice.max()), (0, 255)).astype(np.uint8)\n",
        "\n",
        "                    img = Image.fromarray(resized_slice)\n",
        "\n",
        "                    img.save(output_path)\n",
        "\n",
        "def split_data():\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for label_dir, label in [(tumor_dir, 1), (no_tumor_dir, 0)]:\n",
        "        for img_file in os.listdir(label_dir):\n",
        "            if img_file.endswith('.png'):\n",
        "                images.append(os.path.join(label_dir, img_file))\n",
        "                labels.append(label)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    train_dir = os.path.join(output_dir, 'train')\n",
        "    test_dir = os.path.join(output_dir, 'test')\n",
        "    os.makedirs(train_dir, exist_ok=True)\n",
        "    os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "    for img, label in zip(X_train, y_train):\n",
        "        dest_dir = os.path.join(train_dir, 'Tumor' if label == 1 else 'NoTumor')\n",
        "        os.makedirs(dest_dir, exist_ok=True)\n",
        "        os.rename(img, os.path.join(dest_dir, os.path.basename(img)))\n",
        "\n",
        "    for img, label in zip(X_test, y_test):\n",
        "        dest_dir = os.path.join(test_dir, 'Tumor' if label == 1 else 'NoTumor')\n",
        "        os.makedirs(dest_dir, exist_ok=True)\n",
        "        os.rename(img, os.path.join(dest_dir, os.path.basename(img)))\n",
        "\n",
        "process_data()\n",
        "split_data()"
      ],
      "metadata": {
        "id": "H85LiYG3ddnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_dir = '/content/dataset/processed/train'\n",
        "test_dir = '/content/dataset/processed/test'\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")"
      ],
      "metadata": {
        "id": "Ao6LnEQIkCFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input\n",
        "\n",
        "def build_custom_cnn():\n",
        "    model = Sequential([\n",
        "        Input(shape=(224, 224, 3)),\n",
        "        Conv2D(32, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Conv2D(128, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "PEwhMrUkkTU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = build_custom_cnn()\n",
        "cnn_history = cnn_model.fit(\n",
        "    train_generator,\n",
        "    epochs=25,\n",
        "    validation_data=test_generator\n",
        ")\n",
        "\n",
        "cnn_loss, cnn_acc = cnn_model.evaluate(test_generator)\n",
        "print(f\"Custom CNN Test Accuracy: {cnn_acc * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "1s5cxZOskUz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "train_dir = '/content/dataset/processed/train'\n",
        "test_dir = '/content/dataset/processed/test'\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "img_size = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "def build_custom_cnn():\n",
        "    model = Sequential([\n",
        "        Input(shape=(224, 224, 3)),\n",
        "        Conv2D(32, (3,3), activation='relu'),\n",
        "        MaxPooling2D(),\n",
        "        Conv2D(64, (3,3), activation='relu'),\n",
        "        MaxPooling2D(),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_alexnet():\n",
        "    model = Sequential([\n",
        "        Input(shape=(224,224,3)),\n",
        "        Conv2D(96, (11,11), strides=4, activation='relu'),\n",
        "        MaxPooling2D(pool_size=(3,3), strides=2),\n",
        "        Conv2D(256, (5,5), padding=\"same\", activation='relu'),\n",
        "        MaxPooling2D(pool_size=(3,3), strides=2),\n",
        "        Conv2D(384, (3,3), padding=\"same\", activation='relu'),\n",
        "        Conv2D(384, (3,3), padding=\"same\", activation='relu'),\n",
        "        Conv2D(256, (3,3), padding=\"same\", activation='relu'),\n",
        "        MaxPooling2D(pool_size=(3,3), strides=2),\n",
        "        Flatten(),\n",
        "        Dense(4096, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(4096, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_vgg16():\n",
        "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
        "    base_model.trainable = False\n",
        "    model = Sequential([\n",
        "        base_model,\n",
        "        Flatten(),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "cnn_model = build_custom_cnn()\n",
        "cnn_history = cnn_model.fit(\n",
        "    train_generator,\n",
        "    epochs=25,\n",
        "    validation_data=test_generator\n",
        ")\n",
        "\n",
        "alexnet_model = build_alexnet()\n",
        "alexnet_history = alexnet_model.fit(\n",
        "    train_generator,\n",
        "    epochs=25,\n",
        "    validation_data=test_generator\n",
        ")\n",
        "\n",
        "vgg16_model = build_vgg16()\n",
        "vgg16_history = vgg16_model.fit(\n",
        "    train_generator,\n",
        "    epochs=25,\n",
        "    validation_data=test_generator\n",
        ")\n",
        "\n",
        "def plot_accuracy(history, model_name):\n",
        "    plt.figure(figsize=(12,5))\n",
        "\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
        "    plt.title(f'{model_name} - Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "    plt.title(f'{model_name} - Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_accuracy(cnn_history, \"Custom CNN\")\n",
        "plot_accuracy(alexnet_history, \"AlexNet\")\n",
        "plot_accuracy(vgg16_history, \"VGG16\")\n",
        "\n",
        "cnn_eval = cnn_model.evaluate(test_generator, verbose=0)\n",
        "alexnet_eval = alexnet_model.evaluate(test_generator, verbose=0)\n",
        "vgg16_eval = vgg16_model.evaluate(test_generator, verbose=0)\n",
        "\n",
        "print(\"\\n📊 Final Test Accuracies:\")\n",
        "print(f\"Custom CNN:  {cnn_eval[1]*100:.2f}%\")\n",
        "print(f\"AlexNet:     {alexnet_eval[1]*100:.2f}%\")\n",
        "print(f\"VGG16:       {vgg16_eval[1]*100:.2f}%\")"
      ],
      "metadata": {
        "id": "0G63tkMU1ONP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "volume_paths = [\n",
        "    '/content/output/volume_pt1',\n",
        "    '/content/output/volume_pt2',\n",
        "    '/content/output/volume_pt3',\n",
        "    '/content/output/volume_pt4',\n",
        "    '/content/output/volume_pt5'\n",
        "]\n",
        "segmentation_path = '/content/output/segmentations'\n",
        "\n",
        "output_images_folder = '/content/rcnn_dataset/images'\n",
        "output_labels_folder = '/content/rcnn_dataset/labels'\n",
        "\n",
        "os.makedirs(output_images_folder, exist_ok=True)\n",
        "os.makedirs(output_labels_folder, exist_ok=True)\n",
        "\n",
        "def extract_bounding_boxes(mask):\n",
        "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    boxes = []\n",
        "    for contour in contours:\n",
        "        x, y, w, h = cv2.boundingRect(contour)\n",
        "        boxes.append([x, y, x+w, y+h])\n",
        "    return boxes\n",
        "\n",
        "image_counter = 0\n",
        "for volume_dir in volume_paths:\n",
        "    volume_files = os.listdir(volume_dir)\n",
        "\n",
        "    for file_name in tqdm(volume_files):\n",
        "        volume_file = os.path.join(volume_dir, file_name)\n",
        "        segmentation_file = os.path.join(segmentation_path, file_name)\n",
        "\n",
        "        if not os.path.exists(segmentation_file):\n",
        "            continue\n",
        "\n",
        "        volume = nib.load(volume_file).get_fdata()\n",
        "        segmentation = nib.load(segmentation_file).get_fdata()\n",
        "\n",
        "        for slice_idx in range(volume.shape[2]):\n",
        "            image_slice = volume[:, :, slice_idx]\n",
        "            mask_slice = segmentation[:, :, slice_idx]\n",
        "\n",
        "            binary_mask = np.where((mask_slice == 1) | (mask_slice == 2), 1, 0).astype(np.uint8)\n",
        "\n",
        "            if np.sum(binary_mask) == 0:\n",
        "                continue\n",
        "\n",
        "            img = image_slice - np.min(image_slice)\n",
        "            img = (img / np.max(img) * 255).astype(np.uint8)\n",
        "            img = cv2.resize(img, (224, 224))\n",
        "            binary_mask = cv2.resize(binary_mask, (224, 224), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "            img_filename = f\"{image_counter:05d}.png\"\n",
        "            cv2.imwrite(os.path.join(output_images_folder, img_filename), img)\n",
        "\n",
        "            boxes = extract_bounding_boxes(binary_mask)\n",
        "\n",
        "            label_filename = f\"{image_counter:05d}.txt\"\n",
        "            with open(os.path.join(output_labels_folder, label_filename), 'w') as f:\n",
        "                for box in boxes:\n",
        "                    x_min, y_min, x_max, y_max = box\n",
        "                    x_center = (x_min + x_max) / 2 / 224\n",
        "                    y_center = (y_min + y_max) / 2 / 224\n",
        "                    width = (x_max - x_min) / 224\n",
        "                    height = (y_max - y_min) / 224\n",
        "                    f.write(f\"0 {x_center} {y_center} {width} {height}\\n\")\n",
        "\n",
        "            image_counter += 1\n",
        "\n",
        "print(\"Bounding box dataset created successfully ✅\")"
      ],
      "metadata": {
        "id": "axy5FNWlHtR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision --quiet"
      ],
      "metadata": {
        "id": "ScQVGaZuHwgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torchvision\n",
        "from torchvision.transforms import functional as F\n",
        "\n",
        "class TumorDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, images_dir, labels_dir, transforms=None):\n",
        "        self.images_dir = images_dir\n",
        "        self.labels_dir = labels_dir\n",
        "        self.transforms = transforms\n",
        "        self.imgs = list(sorted(os.listdir(images_dir)))\n",
        "        self.labels = list(sorted(os.listdir(labels_dir)))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.images_dir, self.imgs[idx])\n",
        "        label_path = os.path.join(self.labels_dir, self.labels[idx])\n",
        "\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        boxes = []\n",
        "        labels = []\n",
        "\n",
        "        with open(label_path) as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                cls, x_center, y_center, width, height = map(float, parts)\n",
        "\n",
        "                x_min = (x_center - width/2) * 224\n",
        "                y_min = (y_center - height/2) * 224\n",
        "                x_max = (x_center + width/2) * 224\n",
        "                y_max = (y_center + height/2) * 224\n",
        "                boxes.append([x_min, y_min, x_max, y_max])\n",
        "                labels.append(int(cls))\n",
        "\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
        "\n",
        "        target = {}\n",
        "        target[\"boxes\"] = boxes\n",
        "        target[\"labels\"] = labels\n",
        "\n",
        "        if self.transforms:\n",
        "            img = self.transforms(img)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)"
      ],
      "metadata": {
        "id": "CAb95s5rI7Fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "\n",
        "def get_model(num_classes):\n",
        "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "    return model\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "model = get_model(num_classes=2)\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "aLkElvTCJApW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "segmentation_dir = \"/content/output/segmentations\"\n",
        "volume_dir = \"/content/output/volume_pt1\"\n",
        "\n",
        "volume_files = sorted([f for f in os.listdir(volume_dir) if f.endswith('.nii')])\n",
        "\n",
        "for volume_file in volume_files:\n",
        "    volume_number = volume_file.split('-')[1].split('.')[0]\n",
        "    segmentation_filename = f\"segmentation-{volume_number}.nii\"\n",
        "    segmentation_path = os.path.join(segmentation_dir, segmentation_filename)\n",
        "\n",
        "    if os.path.exists(segmentation_path):\n",
        "        print(f\"Found segmentation for {volume_file}: {segmentation_filename}\")\n",
        "    else:\n",
        "        print(f\"Segmentation not found for {volume_file}\")"
      ],
      "metadata": {
        "id": "Ztx_auReJN0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "volume_paths = [f\"/content/output/volume_pt{i}\" for i in range(1,6)]\n",
        "segmentation_path = \"/content/output/segmentations\"\n",
        "\n",
        "save_image_dir = \"/content/rcnn_dataset/images\"\n",
        "save_label_dir = \"/content/rcnn_dataset/labels\"\n",
        "\n",
        "os.makedirs(save_image_dir, exist_ok=True)\n",
        "os.makedirs(save_label_dir, exist_ok=True)\n",
        "\n",
        "def save_slice(image_slice, mask_slice, idx, base_filename):\n",
        "    \"\"\"Save 2D slice image and bounding box\"\"\"\n",
        "    image_slice = (image_slice - np.min(image_slice)) / (np.max(image_slice) - np.min(image_slice) + 1e-8)\n",
        "    image_slice = (image_slice * 255).astype(np.uint8)\n",
        "\n",
        "    tumor_mask = np.logical_or(mask_slice == 1, mask_slice == 2).astype(np.uint8)\n",
        "\n",
        "    contours, _ = cv2.findContours(tumor_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    if len(contours) == 0:\n",
        "        return\n",
        "\n",
        "    image_filename = f\"{base_filename}_{idx:03d}.png\"\n",
        "    label_filename = f\"{base_filename}_{idx:03d}.txt\"\n",
        "    cv2.imwrite(os.path.join(save_image_dir, image_filename), image_slice)\n",
        "\n",
        "    with open(os.path.join(save_label_dir, label_filename), \"w\") as f:\n",
        "        for cnt in contours:\n",
        "            x, y, w, h = cv2.boundingRect(cnt)\n",
        "            if w > 5 and h > 5:\n",
        "                f.write(f\"{x} {y} {x+w} {y+h}\\n\")\n",
        "\n",
        "for part_path in volume_paths:\n",
        "    for file_name in os.listdir(part_path):\n",
        "        if file_name.endswith('.nii') or file_name.endswith('.nii.gz'):\n",
        "            volume_file = os.path.join(part_path, file_name)\n",
        "            seg_file = os.path.join(segmentation_path, file_name)\n",
        "\n",
        "            if not os.path.exists(seg_file):\n",
        "                continue\n",
        "\n",
        "            volume = nib.load(volume_file).get_fdata()\n",
        "            seg = nib.load(seg_file).get_fdata()\n",
        "\n",
        "            for idx in range(volume.shape[2]):\n",
        "                image_slice = volume[:, :, idx]\n",
        "                mask_slice = seg[:, :, idx]\n",
        "                save_slice(image_slice, mask_slice, idx, base_filename=file_name.split('.')[0])\n",
        "\n",
        "print(\"✅ Preprocessing finished. Images and labels saved!\")"
      ],
      "metadata": {
        "id": "u4eOiatqJPtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "\n",
        "volume_dir = '/content/output/volume_pt1/'\n",
        "segmentation_dir = '/content/output/segmentations/'\n",
        "output_dir = '/content/output/sliced_images/'\n",
        "\n",
        "os.makedirs(os.path.join(output_dir, 'Tumor'), exist_ok=True)\n",
        "os.makedirs(os.path.join(output_dir, 'NoTumor'), exist_ok=True)\n",
        "\n",
        "def save_slices(volume, segmentation, volume_filename):\n",
        "    volume_number = volume_filename.split('-')[1].split('.')[0]\n",
        "\n",
        "    num_slices = volume.shape[2]\n",
        "\n",
        "    for i in range(num_slices):\n",
        "        volume_slice = volume[:, :, i]\n",
        "        segmentation_slice = segmentation[:, :, i]\n",
        "\n",
        "        if np.any(segmentation_slice == 1):\n",
        "            label = 'Tumor'\n",
        "        else:\n",
        "            label = 'NoTumor'\n",
        "\n",
        "        slice_filename = f\"{volume_number}_slice_{i}.png\"\n",
        "        slice_path = os.path.join(output_dir, label, slice_filename)\n",
        "\n",
        "        volume_slice = cv2.normalize(volume_slice, None, 0, 255, cv2.NORM_MINMAX)\n",
        "        volume_slice = volume_slice.astype(np.uint8)\n",
        "\n",
        "        cv2.imwrite(slice_path, volume_slice)\n",
        "\n",
        "for volume_filename in os.listdir(volume_dir):\n",
        "    if volume_filename.endswith('.nii'):\n",
        "        volume_path = os.path.join(volume_dir, volume_filename)\n",
        "        volume_img = nib.load(volume_path)\n",
        "        volume_data = volume_img.get_fdata()\n",
        "\n",
        "        segmentation_filename = f\"segmentation-{volume_filename.split('-')[1]}\"\n",
        "        segmentation_path = os.path.join(segmentation_dir, segmentation_filename)\n",
        "\n",
        "        if os.path.exists(segmentation_path):\n",
        "            segmentation_img = nib.load(segmentation_path)\n",
        "            segmentation_data = segmentation_img.get_fdata()\n",
        "\n",
        "            save_slices(volume_data, segmentation_data, volume_filename)\n",
        "            print(f\"Processed: {volume_filename}\")\n",
        "        else:\n",
        "            print(f\"Segmentation not found for {volume_filename}, skipping.\")"
      ],
      "metadata": {
        "id": "WWVTyJWaJXs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "volume_dir = '/content/output/volume_pt1'\n",
        "segmentation_dir = '/content/output/segmentations'\n",
        "output_dir = '/content/sliced_images'\n",
        "\n",
        "os.makedirs(os.path.join(output_dir, 'Tumor'), exist_ok=True)\n",
        "os.makedirs(os.path.join(output_dir, 'NoTumor'), exist_ok=True)\n",
        "\n",
        "print(f\"Volume directory: {volume_dir}\")\n",
        "print(f\"Segmentation directory: {segmentation_dir}\")\n",
        "print(f\"Output directory: {output_dir}\")\n",
        "\n",
        "for volume_filename in os.listdir(volume_dir):\n",
        "    if volume_filename.endswith(\".nii\"):\n",
        "        volume_path = os.path.join(volume_dir, volume_filename)\n",
        "\n",
        "        volume_id = volume_filename.replace(\"volume-\", \"\").replace(\".nii\", \"\")\n",
        "        segmentation_path = os.path.join(segmentation_dir, f\"segmentation-{volume_id}.nii\")\n",
        "\n",
        "        print(f\"Processing volume: {volume_filename} with segmentation: {segmentation_path}\")\n",
        "\n",
        "        volume_nii = nib.load(volume_path)\n",
        "        volume_data = volume_nii.get_fdata()\n",
        "        segmentation_nii = nib.load(segmentation_path)\n",
        "        segmentation_data = segmentation_nii.get_fdata()\n",
        "\n",
        "        for i in range(volume_data.shape[2]):\n",
        "            slice_data = volume_data[:, :, i]\n",
        "            seg_slice_data = segmentation_data[:, :, i]\n",
        "\n",
        "            if np.any(seg_slice_data > 0):\n",
        "                label = 'Tumor'\n",
        "            else:\n",
        "                label = 'NoTumor'\n",
        "\n",
        "            image_filename = f\"{volume_filename.split('.')[0]}_slice_{i}.png\"\n",
        "            save_path = os.path.join(output_dir, label, image_filename)\n",
        "\n",
        "            print(f\"Saving {label} image: {save_path}\")\n",
        "\n",
        "            img = Image.fromarray(slice_data.astype(np.uint8))\n",
        "            img.save(save_path)\n",
        "\n",
        "print(\"Processing completed.\")"
      ],
      "metadata": {
        "id": "g_dCs5xiJ0Kz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "volume_dir = '/content/output/volume_pt1'\n",
        "segmentation_dir = '/content/output/segmentations'\n",
        "output_dir = '/content/sliced_images'\n",
        "\n",
        "tumor_dir = os.path.join(output_dir, \"Tumor\")\n",
        "no_tumor_dir = os.path.join(output_dir, \"NoTumor\")\n",
        "os.makedirs(tumor_dir, exist_ok=True)\n",
        "os.makedirs(no_tumor_dir, exist_ok=True)\n",
        "\n",
        "def normalize_image(img):\n",
        "    img = img - np.min(img)\n",
        "    img = img / (np.max(img) + 1e-8)\n",
        "    img = (img * 255).astype(np.uint8)\n",
        "    return img\n",
        "\n",
        "for volume_filename in tqdm(os.listdir(volume_dir), desc=\"Processing volumes\"):\n",
        "    if volume_filename.endswith(\".nii\"):\n",
        "        volume_path = os.path.join(volume_dir, volume_filename)\n",
        "\n",
        "        volume_id = volume_filename.replace(\"volume-\", \"\").replace(\".nii\", \"\")\n",
        "        segmentation_path = os.path.join(segmentation_dir, f\"segmentation-{volume_id}.nii\")\n",
        "\n",
        "        if not os.path.exists(segmentation_path):\n",
        "            print(f\"Segmentation not found for {volume_filename}, skipping.\")\n",
        "            continue\n",
        "\n",
        "        volume_nii = nib.load(volume_path)\n",
        "        volume_data = volume_nii.get_fdata()\n",
        "\n",
        "        segmentation_nii = nib.load(segmentation_path)\n",
        "        segmentation_data = segmentation_nii.get_fdata()\n",
        "\n",
        "        num_slices = volume_data.shape[2]\n",
        "        for i in range(num_slices):\n",
        "            slice_img = volume_data[:, :, i]\n",
        "            slice_seg = segmentation_data[:, :, i]\n",
        "\n",
        "            if np.max(slice_img) == 0:\n",
        "                continue\n",
        "\n",
        "            slice_img = normalize_image(slice_img)\n",
        "\n",
        "            if np.any(slice_seg == 1) or np.any(slice_seg == 2):\n",
        "                save_path = os.path.join(tumor_dir, f\"{volume_id}_slice_{i}.png\")\n",
        "            else:\n",
        "                save_path = os.path.join(no_tumor_dir, f\"{volume_id}_slice_{i}.png\")\n",
        "\n",
        "            plt.imsave(save_path, slice_img, cmap='gray')\n",
        "\n",
        "print(\"✅ Done saving slices!\")"
      ],
      "metadata": {
        "id": "2ySoBl1dKb5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "tumor_dir = '/content/sliced_images/Tumor'\n",
        "no_tumor_dir = '/content/sliced_images/NoTumor'\n",
        "\n",
        "tumor_samples = random.sample(os.listdir(tumor_dir), min(5, len(os.listdir(tumor_dir))))\n",
        "no_tumor_samples = random.sample(os.listdir(no_tumor_dir), min(5, len(os.listdir(no_tumor_dir))))\n",
        "\n",
        "fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
        "\n",
        "for idx, img_name in enumerate(tumor_samples):\n",
        "    img = mpimg.imread(os.path.join(tumor_dir, img_name))\n",
        "    axes[0, idx].imshow(img, cmap='gray')\n",
        "    axes[0, idx].set_title(f\"Tumor: {img_name}\")\n",
        "    axes[0, idx].axis('off')\n",
        "\n",
        "for idx, img_name in enumerate(no_tumor_samples):\n",
        "    img = mpimg.imread(os.path.join(no_tumor_dir, img_name))\n",
        "    axes[1, idx].imshow(img, cmap='gray')\n",
        "    axes[1, idx].set_title(f\"No Tumor: {img_name}\")\n",
        "    axes[1, idx].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "A5goaZgyMc6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.io import read_image\n",
        "\n",
        "class TumorDataset(Dataset):\n",
        "    def __init__(self, image_dir, transforms=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.transforms = transforms\n",
        "        self.images = list(sorted(os.listdir(image_dir)))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.image_dir, self.images[idx])\n",
        "        img = read_image(img_path).float() / 255.0\n",
        "\n",
        "        label = 1 if \"Tumor\" in self.images[idx] else 0\n",
        "\n",
        "        target = {}\n",
        "        target['labels'] = torch.tensor([label], dtype=torch.int64)\n",
        "        target['boxes'] = torch.tensor([[0, 0, img.shape[2], img.shape[1]]], dtype=torch.float32)\n",
        "        target['image_id'] = torch.tensor([idx])\n",
        "\n",
        "        if self.transforms:\n",
        "            img = self.transforms(img)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)"
      ],
      "metadata": {
        "id": "6wk4tOQFNnD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "\n",
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, 2)"
      ],
      "metadata": {
        "id": "_7mQpqLJNrua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))"
      ],
      "metadata": {
        "id": "RlRSUIg9NvUr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}